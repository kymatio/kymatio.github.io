{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRegularized inverse of a scattering transform on MNIST\n======================================================\n\nDescription:\nThis example trains a convolutional network to invert the scattering transform at scale 2 of MNIST digits.\nAfter only two epochs, it produces a network that transforms a linear interpolation in the scattering space into a\nnonlinear interpolation in the image space.\n\nRemarks:\nThe model after two epochs and the path (which consists of a sequence of images) are stored in the cache directory.\nThe two epochs take roughly 5 minutes in a Quadro M6000.\n\nReference:\nhttps://arxiv.org/abs/1805.06621\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nfrom kymatio import Scattering2D as Scattering\nfrom kymatio.caching import get_cache_dir\nfrom kymatio.datasets import get_dataset_dir\n\n\nclass Generator(nn.Module):\n    def __init__(self, num_input_channels, num_hidden_channels, num_output_channels=1, filter_size=3):\n        super(Generator, self).__init__()\n        self.num_input_channels = num_input_channels\n        self.num_hidden_channels = num_hidden_channels\n        self.num_output_channels = num_output_channels\n        self.filter_size = filter_size\n        self.build()\n\n    def build(self):\n        padding = (self.filter_size - 1) // 2\n\n        self.main = nn.Sequential(\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_input_channels, self.num_hidden_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_hidden_channels, eps=0.001, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_hidden_channels, self.num_hidden_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_hidden_channels, eps=0.001, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_hidden_channels, self.num_output_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_output_channels, eps=0.001, momentum=0.9),\n            nn.Tanh()\n        )\n\n    def forward(self, input_tensor):\n        return self.main(input_tensor)\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Regularized inverse scattering')\n    parser.add_argument('--num_epochs', default=2, help='Number of epochs to train')\n    parser.add_argument('--load_model', default=False, help='Load a trained model?')\n    parser.add_argument('--dir_save_images', default='interpolation_images', help='Dir to save the sequence of images')\n    args = parser.parse_args()\n\n    num_epochs = args.num_epochs\n    load_model = args.load_model\n    dir_save_images = args.dir_save_images\n\n    dir_to_save = get_cache_dir('reg_inverse_example')\n\n    transforms_to_apply = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Pixel values should be in [-1,1]\n    ])\n\n    mnist_dir = get_dataset_dir(\"MNIST\", create=True)\n    dataset = datasets.MNIST(mnist_dir, train=True, download=True, transform=transforms_to_apply)\n    dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n\n    fixed_dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n    fixed_batch = next(iter(fixed_dataloader))\n    fixed_batch = fixed_batch[0].float().cuda()\n\n    scattering = Scattering(J=2, shape=(28, 28))\n    scattering.cuda()\n\n    scattering_fixed_batch = scattering(fixed_batch).squeeze(1)\n    num_input_channels = scattering_fixed_batch.shape[1]\n    num_hidden_channels = num_input_channels\n\n    generator = Generator(num_input_channels, num_hidden_channels)\n    generator.cuda()\n    generator.train()\n\n    # Either train the network or load a trained model\n    ##################################################\n    if load_model:\n        filename_model = os.path.join(dir_to_save, 'model.pth')\n        generator.load_state_dict(torch.load(filename_model))\n    else:\n        criterion = torch.nn.L1Loss()\n        optimizer = optim.Adam(generator.parameters())\n\n        for idx_epoch in range(num_epochs):\n            print('Training epoch {}'.format(idx_epoch))\n            for _, current_batch in enumerate(dataloader):\n                generator.zero_grad()\n                batch_images = Variable(current_batch[0]).float().cuda()\n                batch_scattering = scattering(batch_images).squeeze(1)\n                batch_inverse_scattering = generator(batch_scattering)\n                loss = criterion(batch_inverse_scattering, batch_images)\n                loss.backward()\n                optimizer.step()\n\n        print('Saving results in {}'.format(dir_to_save))\n\n        torch.save(generator.state_dict(), os.path.join(dir_to_save, 'model.pth'))\n\n    generator.eval()\n\n    # We create the batch containing the linear interpolation points in the scattering space\n    ########################################################################################\n    z0 = scattering_fixed_batch.cpu().numpy()[[0]]\n    z1 = scattering_fixed_batch.cpu().numpy()[[1]]\n    batch_z = np.copy(z0)\n    num_samples = 32\n    interval = np.linspace(0, 1, num_samples)\n    for t in interval:\n        if t > 0:\n            zt = (1 - t) * z0 + t * z1\n            batch_z = np.vstack((batch_z, zt))\n\n    z = torch.from_numpy(batch_z).float().cuda()\n    path = generator(z).data.cpu().numpy().squeeze(1)\n    path = (path + 1) / 2  # The pixels are now in [0, 1]\n\n    # We show and store the nonlinear interpolation in the image space\n    ##################################################################\n    dir_path = os.path.join(dir_to_save, dir_save_images)\n\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)\n\n    for idx_image in range(num_samples):\n        current_image = np.uint8(path[idx_image] * 255.0)\n        filename = os.path.join(dir_path, '{}.png'.format(idx_image))\n        Image.fromarray(current_image).save(filename)\n        plt.imshow(current_image, cmap='gray')\n        plt.axis('off')\n        plt.pause(0.1)\n        plt.draw()\n\n\nif __name__ == '__main__':\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Classification of spoken digit recordings\n\nIn this example we use the 1D scattering transform to represent spoken digits,\nwhich we then classify using a simple classifier. This shows that 1D scattering\nrepresentations are useful for this type of problem.\n\nThis dataset is automatically downloaded and preprocessed from\nhttps://github.com/Jakobovski/free-spoken-digit-dataset.git\n\nDownloading and precomputing scattering coefficients should take about 5 min.\nRunning the gradient descent takes about 1 min.\n\nResults:\nTraining accuracy = 99.7%\nTesting accuracy = 98.0%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preliminaries\n\nSince we're using TensorFlow and Keras to train the model, import the\nrelevant modules.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n\nfrom tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To handle audio file I/O, we import `os` and `scipy.io.wavfile`. We also need\n`numpy` for some basic array manipulation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile\nimport os\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we import the `Scattering1D` class from the `kymatio.keras` package\nand the `fetch_fsdd` function from `kymatio.datasets`. The `Scattering1D`\nclass is what lets us calculate the scattering transform, while the\n`fetch_fsdd` function downloads the FSDD, if needed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from kymatio.keras import Scattering1D\nfrom kymatio.datasets import fetch_fsdd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline setup\nWe start by specifying the dimensions of our processing pipeline along with\nsome other parameters.\n\nFirst, we have signal length. Longer signals are truncated and shorter\nsignals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\nlittle over a second.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "T = 2 ** 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\nand the number of wavelets per octave.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "J = 8\nQ = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need a small constant to add to the scattering coefficients before\ncomputing the logarithm. This prevents very large values when the scattering\ncoefficients are very close to zero.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_eps = 1e-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data\nOnce the parameter are set, we can start loading the data into a format that\ncan be fed into the scattering transform and then a logistic regression\nclassifier.\n\nWe first download the dataset. If it's already downloaded, `fetch_fsdd` will\nsimply return the information corresponding to the dataset that's already\non disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "info_data = fetch_fsdd()\nfiles = info_data['files']\npath_dataset = info_data['path_dataset']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up NumPy arrays to hold the audio signals (`x_all`), the labels\n(`y_all`), and whether the signal is in the train or test set (`subset`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_all = np.zeros((len(files), T))\ny_all = np.zeros(len(files), dtype=np.uint8)\nsubset = np.zeros(len(files), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each file in the dataset, we extract its label `y` and its index from the\nfilename. If the index is between 0 and 4, it is placed in the test set, while\nfiles with larger indices are used for training. The actual signals are\nnormalized to have maximum amplitude one, and are truncated or zero-padded\nto the desired length `T`. They are then stored in the `x_all` array while\ntheir labels are in `y_all`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for k, f in enumerate(files):\n    basename = f.split('.')[0]\n\n    # Get label (0-9) of recording.\n    y = int(basename.split('_')[0])\n\n    # Index larger than 5 gets assigned to training set.\n    if int(basename.split('_')[2]) >= 5:\n        subset[k] = 0\n    else:\n        subset[k] = 1\n\n    # Load the audio signal and normalize it.\n    _, x = wavfile.read(os.path.join(path_dataset, f))\n    x = np.asarray(x, dtype='float')\n    x /= np.max(np.abs(x))\n\n    # If it's too long, truncate it.\n    if len(x) > T:\n        x = x[:T]\n\n    # If it's too short, zero-pad it.\n    start = (T - len(x)) // 2\n\n    x_all[k,start:start + len(x)] = x\n    y_all[k] = y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log-scattering layer\nWe now create a classification model using the `Scattering1D` Keras layer.\nFirst, we take the input signals of length `T`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_in = layers.Input(shape=(T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are fed into the `Scattering1D` layer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = Scattering1D(J, Q=Q)(x_in)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since it does not carry useful information, we remove the zeroth-order\nscattering coefficients, which are always placed in the first channel of\nthe scattering transform.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = layers.Lambda(lambda x: x[..., 1:, :])(x)\n\n# To increase discriminability, we take the logarithm of the scattering\n# coefficients (after adding a small constant to make sure nothing blows up\n# when scattering coefficients are close to zero). This is known as the\n# log-scattering transform.\n\nx = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then average along the last dimension (time) to get a time-shift\ninvariant representation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = layers.GlobalAveragePooling1D(data_format='channels_first')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we apply batch normalization to ensure that the data is within a\nmoderate range.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = layers.BatchNormalization(axis=1)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These features are then used to classify the input signal using a dense\nlayer followed by a softmax activation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_out = layers.Dense(10, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create the model and display it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Model(x_in, x_out)\nmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the classifier\nHaving set up the model, we attach an Adam optimizer and a cross-entropy\nloss function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then train the model using `model.fit`. The training data is given by\nthose indices satisfying `subset == 0`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.fit(x_all[subset == 0], y_all[subset == 0], epochs=50,\n          batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we evaluate the model on the held-out test data. These are given by\nthe indices `subset == 1`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_all[subset == 1], y_all[subset == 1], verbose=2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Classification of spoken digit recordings &#8212; kymatio 0.3.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/kymatio.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2D examples" href="../gallery_2d/index.html" />
    <link rel="prev" title="Reconstruct a synthetic signal from its scattering transform" href="reconstruct_torch.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
    <link rel="apple-touch-icon" href="../_static/kymatio.jpg" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gallery-1d-plot-classif-torch-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="classification-of-spoken-digit-recordings">
<span id="sphx-glr-gallery-1d-plot-classif-torch-py"></span><h1>Classification of spoken digit recordings<a class="headerlink" href="#classification-of-spoken-digit-recordings" title="Permalink to this heading">¶</a></h1>
<p>In this example we use the 1D scattering transform to represent spoken digits,
which we then classify using a simple classifier. This shows that 1D scattering
representations are useful for this type of problem.</p>
<p>This dataset is automatically downloaded and preprocessed from
<a class="reference external" href="https://github.com/Jakobovski/free-spoken-digit-dataset.git">https://github.com/Jakobovski/free-spoken-digit-dataset.git</a></p>
<p>Downloading and precomputing scattering coefficients should take about 5 min.
Running the gradient descent takes about 1 min.</p>
<p>Results:
Training accuracy = 99.7%
Testing accuracy = 98.0%</p>
<section id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this heading">¶</a></h2>
<p>Since we’re using PyTorch to train the model, import <cite>torch</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<p>We will be constructing a logistic regression classifier on top of the
scattering coefficients, so we need some of the neural network tools from
<cite>torch.nn</cite> and the Adam optimizer from <cite>torch.optim</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">NLLLoss</span><span class="p">,</span> <span class="n">LogSoftmax</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
</pre></div>
</div>
<p>To handle audio file I/O, we import <cite>os</cite> and <cite>scipy.io.wavfile</cite>. We also need
<cite>numpy</cite> for some basic array manipulation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">wavfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
<p>To evaluate our results, we need to form a confusion matrix using
scikit-learn and display them using <cite>matplotlib</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<p>Finally, we import the <cite>Scattering1D</cite> class from the <cite>kymatio.torch</cite> package
and the <cite>fetch_fsdd</cite> function from <cite>kymatio.datasets</cite>. The <cite>Scattering1D</cite>
class is what lets us calculate the scattering transform, while the
<cite>fetch_fsdd</cite> function downloads the FSDD, if needed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kymatio.torch</span> <span class="kn">import</span> <span class="n">Scattering1D</span>
<span class="kn">from</span> <span class="nn">kymatio.datasets</span> <span class="kn">import</span> <span class="n">fetch_fsdd</span>
</pre></div>
</div>
</section>
<section id="pipeline-setup">
<h2>Pipeline setup<a class="headerlink" href="#pipeline-setup" title="Permalink to this heading">¶</a></h2>
<p>We start by specifying the dimensions of our processing pipeline along with
some other parameters.</p>
<p>First, we have signal length. Longer signals are truncated and shorter
signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to
little over a second.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">13</span>
</pre></div>
</div>
<p>Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)
and the number of wavelets per octave.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">J</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">Q</span> <span class="o">=</span> <span class="mi">12</span>
</pre></div>
</div>
<p>We need a small constant to add to the scattering coefficients before
computing the logarithm. This prevents very large values when the scattering
coefficients are very close to zero.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">log_eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
</pre></div>
</div>
<p>If a GPU is available, let’s use it!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>For reproducibility, we fix the seed of the random number generator.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;torch._C.Generator object at 0x7f365969cf90&gt;
</pre></div>
</div>
</section>
<section id="loading-the-data">
<h2>Loading the data<a class="headerlink" href="#loading-the-data" title="Permalink to this heading">¶</a></h2>
<p>Once the parameter are set, we can start loading the data into a format that
can be fed into the scattering transform and then a logistic regression
classifier.</p>
<p>We first download the dataset. If it’s already downloaded, <cite>fetch_fsdd</cite> will
simply return the information corresponding to the dataset that’s already
on disk.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">info_data</span> <span class="o">=</span> <span class="n">fetch_fsdd</span><span class="p">()</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">info_data</span><span class="p">[</span><span class="s1">&#39;files&#39;</span><span class="p">]</span>
<span class="n">path_dataset</span> <span class="o">=</span> <span class="n">info_data</span><span class="p">[</span><span class="s1">&#39;path_dataset&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Set up Tensors to hold the audio signals (<cite>x_all</cite>), the labels (<cite>y_all</cite>), and
whether the signal is in the train or test set (<cite>subset</cite>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">),</span> <span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">subset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>For each file in the dataset, we extract its label <cite>y</cite> and its index from the
filename. If the index is between 0 and 4, it is placed in the test set, while
files with larger indices are used for training. The actual signals are
normalized to have maximum amplitude one, and are truncated or zero-padded
to the desired length <cite>T</cite>. They are then stored in the <cite>x_all</cite> Tensor while
their labels are in <cite>y_all</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">files</span><span class="p">):</span>
    <span class="n">basename</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Get label (0-9) of recording.</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">basename</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Index larger than 5 gets assigned to training set.</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">basename</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">subset</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">subset</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Load the audio signal and normalize it.</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">wavfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_dataset</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="c1"># Convert from NumPy array to PyTorch Tensor.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># If it&#39;s too long, truncate it.</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">T</span><span class="p">]</span>

    <span class="c1"># If it&#39;s too short, zero-pad it.</span>
    <span class="n">start</span> <span class="o">=</span> <span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="n">x_all</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">start</span><span class="p">:</span><span class="n">start</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()]</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">y_all</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
</pre></div>
</div>
</section>
<section id="log-scattering-transform">
<h2>Log-scattering transform<a class="headerlink" href="#log-scattering-transform" title="Permalink to this heading">¶</a></h2>
<p>We now create the <cite>Scattering1D</cite> object that will be used to calculate the
scattering coefficients.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scattering</span> <span class="o">=</span> <span class="n">Scattering1D</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Compute the scattering transform for all signals in the dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_all</span> <span class="o">=</span> <span class="n">scattering</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_all</span><span class="p">)</span>
</pre></div>
</div>
<p>Since it does not carry useful information, we remove the zeroth-order
scattering coefficients, which are always placed in the first channel of
the scattering Tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_all</span> <span class="o">=</span> <span class="n">Sx_all</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:,:]</span>
</pre></div>
</div>
<p>To increase discriminability, we take the logarithm of the scattering
coefficients (after adding a small constant to make sure nothing blows up
when scattering coefficients are close to zero). This is known as the
log-scattering transform.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Sx_all</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_eps</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we average along the last dimension (time) to get a time-shift
invariant representation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Sx_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-the-classifier">
<h2>Training the classifier<a class="headerlink" href="#training-the-classifier" title="Permalink to this heading">¶</a></h2>
<p>With the log-scattering coefficients in hand, we are ready to train our
logistic regression classifier.</p>
<p>First, we extract the training data (those for which <cite>subset</cite> equals <cite>0</cite>)
and the associated labels.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_tr</span><span class="p">,</span> <span class="n">y_tr</span> <span class="o">=</span> <span class="n">Sx_all</span><span class="p">[</span><span class="n">subset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_all</span><span class="p">[</span><span class="n">subset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Standardize the data to have mean zero and unit variance. Note that we need
to apply the same transformation to the test data later, so we save the
mean and standard deviation Tensors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mu_tr</span> <span class="o">=</span> <span class="n">Sx_tr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std_tr</span> <span class="o">=</span> <span class="n">Sx_tr</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Sx_tr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sx_tr</span> <span class="o">-</span> <span class="n">mu_tr</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_tr</span>
</pre></div>
</div>
<p>Here we define a logistic regression model using PyTorch. We train it using
Adam with a negative log-likelihood loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_input</span> <span class="o">=</span> <span class="n">Sx_tr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">y_tr</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_input</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span> <span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">NLLLoss</span><span class="p">()</span>
</pre></div>
</div>
<p>If we’re on a GPU, transfer the model and the loss function onto the device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Before training the model, we set some parameters for the optimization
procedure.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of signals to use in each gradient descent step (batch).</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># Number of epochs.</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Learning rate for Adam.</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span>
</pre></div>
</div>
<p>Given these parameters, we compute the total number of batches.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsamples</span> <span class="o">=</span> <span class="n">Sx_tr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nbatches</span> <span class="o">=</span> <span class="n">nsamples</span> <span class="o">//</span> <span class="n">batch_size</span>
</pre></div>
</div>
<p>Now we’re ready to train the classifier.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Randomly permute the data. If necessary, transfer the permutation to the</span>
    <span class="c1"># GPU.</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># For each batch, calculate the gradient with respect to the loss and take</span>
    <span class="c1"># one step.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbatches</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Sx_tr</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Calculate the response of the training data at the end of this epoch and</span>
    <span class="c1"># the average loss.</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Sx_tr</span><span class="p">)</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>

    <span class="c1"># Try predicting the classes of the signals in the training set and compute</span>
    <span class="c1"># the accuracy.</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_tr</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">, average loss = </span><span class="si">{:1.3f}</span><span class="s1">, accuracy = </span><span class="si">{:1.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">e</span><span class="p">,</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 0, average loss = 0.727, accuracy = 0.816
Epoch 1, average loss = 0.508, accuracy = 0.879
Epoch 2, average loss = 0.407, accuracy = 0.909
Epoch 3, average loss = 0.347, accuracy = 0.919
Epoch 4, average loss = 0.308, accuracy = 0.927
Epoch 5, average loss = 0.280, accuracy = 0.938
Epoch 6, average loss = 0.256, accuracy = 0.942
Epoch 7, average loss = 0.236, accuracy = 0.947
Epoch 8, average loss = 0.219, accuracy = 0.950
Epoch 9, average loss = 0.207, accuracy = 0.952
Epoch 10, average loss = 0.197, accuracy = 0.953
Epoch 11, average loss = 0.185, accuracy = 0.956
Epoch 12, average loss = 0.178, accuracy = 0.959
Epoch 13, average loss = 0.165, accuracy = 0.962
Epoch 14, average loss = 0.160, accuracy = 0.961
Epoch 15, average loss = 0.152, accuracy = 0.965
Epoch 16, average loss = 0.148, accuracy = 0.964
Epoch 17, average loss = 0.141, accuracy = 0.970
Epoch 18, average loss = 0.137, accuracy = 0.970
Epoch 19, average loss = 0.131, accuracy = 0.971
Epoch 20, average loss = 0.127, accuracy = 0.973
Epoch 21, average loss = 0.122, accuracy = 0.977
Epoch 22, average loss = 0.119, accuracy = 0.974
Epoch 23, average loss = 0.115, accuracy = 0.978
Epoch 24, average loss = 0.113, accuracy = 0.973
Epoch 25, average loss = 0.109, accuracy = 0.977
Epoch 26, average loss = 0.104, accuracy = 0.980
Epoch 27, average loss = 0.106, accuracy = 0.981
Epoch 28, average loss = 0.107, accuracy = 0.976
Epoch 29, average loss = 0.098, accuracy = 0.980
Epoch 30, average loss = 0.094, accuracy = 0.983
Epoch 31, average loss = 0.093, accuracy = 0.981
Epoch 32, average loss = 0.094, accuracy = 0.979
Epoch 33, average loss = 0.091, accuracy = 0.983
Epoch 34, average loss = 0.086, accuracy = 0.983
Epoch 35, average loss = 0.085, accuracy = 0.985
Epoch 36, average loss = 0.082, accuracy = 0.983
Epoch 37, average loss = 0.081, accuracy = 0.986
Epoch 38, average loss = 0.077, accuracy = 0.987
Epoch 39, average loss = 0.077, accuracy = 0.984
Epoch 40, average loss = 0.074, accuracy = 0.987
Epoch 41, average loss = 0.072, accuracy = 0.988
Epoch 42, average loss = 0.072, accuracy = 0.989
Epoch 43, average loss = 0.071, accuracy = 0.989
Epoch 44, average loss = 0.070, accuracy = 0.987
Epoch 45, average loss = 0.068, accuracy = 0.989
Epoch 46, average loss = 0.066, accuracy = 0.987
Epoch 47, average loss = 0.065, accuracy = 0.991
Epoch 48, average loss = 0.064, accuracy = 0.989
Epoch 49, average loss = 0.062, accuracy = 0.991
</pre></div>
</div>
<p>Now that our network is trained, let’s test it!</p>
<p>First, we extract the test data (those for which <cite>subset</cite> equals <cite>1</cite>) and the
associated labels.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_te</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">Sx_all</span><span class="p">[</span><span class="n">subset</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_all</span><span class="p">[</span><span class="n">subset</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Use the mean and standard deviation calculated on the training data to
standardize the testing data, as well.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sx_te</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sx_te</span> <span class="o">-</span> <span class="n">mu_tr</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_tr</span>
</pre></div>
</div>
<p>Calculate the response of the classifier on the test data and the resulting
loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">resp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Sx_te</span><span class="p">)</span>
<span class="n">avg_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">y_te</span><span class="p">)</span>

<span class="c1"># Try predicting the labels of the signals in the test data and compute the</span>
<span class="c1"># accuracy.</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">accu</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_te</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST, average loss = </span><span class="si">{:1.3f}</span><span class="s1">, accuracy = </span><span class="si">{:1.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
      <span class="n">avg_loss</span><span class="p">,</span> <span class="n">accu</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TEST, average loss = 0.110, accuracy = 0.967
</pre></div>
</div>
</section>
<section id="plotting-the-classification-accuracy-as-a-confusion-matrix">
<h2>Plotting the classification accuracy as a confusion matrix<a class="headerlink" href="#plotting-the-classification-accuracy-as-a-confusion-matrix" title="Permalink to this heading">¶</a></h2>
<p>Let’s see what the very few misclassified sounds get misclassified as. We
will plot a confusion matrix which indicates in a 2D histogram how often
one sample was mistaken for another (anything on the diagonal is correctly
classified, anything off the diagonal is wrong).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_categories</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">actual_categories</span> <span class="o">=</span> <span class="n">y_te</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">actual_categories</span><span class="p">,</span> <span class="n">predicted_categories</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">confusion</span><span class="p">)</span>
<span class="n">tick_locs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_locs</span><span class="p">,</span> <span class="n">ticks</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_locs</span><span class="p">,</span> <span class="n">ticks</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True number&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted number&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_classif_torch_001.png" srcset="../_images/sphx_glr_plot_classif_torch_001.png" alt="plot classif torch" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 2 minutes  2.280 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-gallery-1d-plot-classif-torch-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/d670c546d76122dc528274b4a6c25773/plot_classif_torch.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_classif_torch.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/68cb7ba06b277cb251736c0c8dec2e03/plot_classif_torch.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_classif_torch.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/kymatio.jpg" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Wavelet Scattering in Python<br>&nbsp;&nbsp;&nbsp;<a href="https://twitter.com/KymatioWavelets"><img width="40px" src="https://avatars3.githubusercontent.com/u/50278?s=200&v=4"></a></p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=kymatio&repo=kymatio&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../userguide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developerguide.html">Information for developers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../codereference.html">Documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">1D examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_real_signal.html">Compute the scattering transform of a speech recording</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_filters.html">Plot the 1D wavelet filters</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_synthetic.html">Compute the scattering transform of a synthetic signal</a></li>
<li class="toctree-l2"><a class="reference internal" href="classif_keras.html">Classification of spoken digit recordings</a></li>
<li class="toctree-l2"><a class="reference internal" href="reconstruct_torch.html">Reconstruct a synthetic signal from its scattering transform</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Classification of spoken digit recordings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#preliminaries">Preliminaries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pipeline-setup">Pipeline setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-the-data">Loading the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-scattering-transform">Log-scattering transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-classifier">Training the classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#plotting-the-classification-accuracy-as-a-confusion-matrix">Plotting the classification accuracy as a confusion matrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gallery_2d/index.html">2D examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gallery_3d/index.html">3D examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">What’s New</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">1D examples</a><ul>
      <li>Previous: <a href="reconstruct_torch.html" title="previous chapter">Reconstruct a synthetic signal from its scattering transform</a></li>
      <li>Next: <a href="../gallery_2d/index.html" title="next chapter">2D examples</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018–2021, The Kymatio Developers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/gallery_1d/plot_classif_torch.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/kymatio/kymatio" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-130785726-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>